{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "McraDkpdn0cL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from IPython.display import Image  # for displaying images\n",
        "import os \n",
        "import random\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xml.etree.ElementTree as ET\n",
        "from xml.dom import minidom\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "random.seed(108)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lj3Lt1B27B78"
      },
      "source": [
        "Training images set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-GQBc00qXc1",
        "outputId": "eb425e06-9c37-4592-85b0-1badc40fdeca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niwMcNT-6DwE"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d andrewmvd/road-sign-detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Htot3DwjI3i9"
      },
      "outputs": [],
      "source": [
        "!unzip /content/road-sign-detection.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3fNt2dShPSG"
      },
      "outputs": [],
      "source": [
        "!curl -L \"https://public.roboflow.com/ds/ONxyYx8ddR?key=36n4EfSQY5\" > roboflow.zip; "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLWfRSezIMi0"
      },
      "outputs": [],
      "source": [
        "!unzip roboflow.zip;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6hKHi5EHC-b",
        "outputId": "71b7d75e-070e-4b4e-e2e5-3a4b32219e57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total OLD images:  29800\n",
            "total OLD labels:  29800\n"
          ]
        }
      ],
      "source": [
        "imagesFolder = \"/content/export/images/\"\n",
        "labelsFolder = \"/content/export/labels/\"\n",
        "\n",
        "images = os.listdir(imagesFolder)\n",
        "labels = os.listdir(labelsFolder)\n",
        "\n",
        "\n",
        "print('total OLD images: ', len(images))\n",
        "print('total OLD labels: ', len(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BKQqUdbzE8En",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "889b1c88-c343-420e-a8f8-11d7c5e16cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 0.25416666666666665 0.5433333333333333 0.08958333333333333 0.07666666666666667\n",
            "\n",
            "1 0.2520833333333333 0.545 0.07708333333333334 0.07666666666666667\n"
          ]
        }
      ],
      "source": [
        "i = 222\n",
        "labelPath = labelsFolder + os.listdir(labelsFolder)[i]\n",
        "f = open(labelPath, \"r\")\n",
        "txtFileContent = \"\"\n",
        "\n",
        "for x in f:\n",
        "  print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8B6CoFVII5D_"
      },
      "outputs": [],
      "source": [
        "n = 3\n",
        "replacementStr = 'jpg'\n",
        "\n",
        "for i in range(len(labels)):\n",
        "\n",
        "    labelPath = labelsFolder + labels[i]\n",
        "    f = open(labelPath, \"r\")\n",
        "    txtFileContent = \"\"\n",
        "    \n",
        "    for x in f:\n",
        "      if((x[0]=='1' or x[0] == '2' or x[0] ==  '4' or x[0] == '6' ) and (x[1] == ' ')):\n",
        "        txtFileContent += x\n",
        "\n",
        "    f.close()\n",
        "    os.remove(labelPath)\n",
        "\n",
        "    if(txtFileContent!=\"\"):\n",
        "        f = open(labelPath, \"w\")\n",
        "        f.write(txtFileContent)\n",
        "        f.close()\n",
        "    else:\n",
        "        # Replace last 3 characters in labels with 'jpg'\n",
        "\n",
        "        pathToImageBeingRemoved = imagesFolder + labels[i][:-n] + replacementStr\n",
        "\n",
        "        os.remove(pathToImageBeingRemoved)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsCav5J5FdF0",
        "outputId": "1dc1be98-d8ef-4848-c3e8-2171baacc142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 0.0634765625 0.5419921875 0.05078125 0.0537109375\n",
            "\n",
            "1 0.0244140625 0.5361328125 0.046875 0.0771484375\n",
            "\n",
            "1 0.1162109375 0.5087890625 0.048828125 0.03125\n",
            "\n",
            "1 0.142578125 0.505859375 0.0302734375 0.03125\n",
            "\n",
            "1 0.1728515625 0.5087890625 0.0400390625 0.0302734375\n",
            "\n",
            "1 0.1826171875 0.49609375 0.04296875 0.0283203125\n",
            "\n",
            "1 0.2138671875 0.4970703125 0.029296875 0.03515625\n",
            "\n",
            "1 0.2294921875 0.52734375 0.0439453125 0.0478515625\n",
            "\n",
            "1 0.228515625 0.525390625 0.0400390625 0.046875\n",
            "\n",
            "1 0.26171875 0.5029296875 0.037109375 0.06640625\n",
            "\n",
            "1 0.3017578125 0.5283203125 0.0634765625 0.0634765625\n",
            "\n",
            "1 0.34375 0.5087890625 0.025390625 0.0302734375\n",
            "\n",
            "1 0.3798828125 0.5048828125 0.025390625 0.033203125\n",
            "\n",
            "4 0.419921875 0.427734375 0.0126953125 0.0283203125\n",
            "\n",
            "4 0.46875 0.470703125 0.0107421875 0.03515625\n",
            "\n",
            "4 0.482421875 0.466796875 0.01171875 0.0302734375\n",
            "\n",
            "1 0.51171875 0.5087890625 0.03515625 0.0498046875\n",
            "\n",
            "1 0.51171875 0.50390625 0.0283203125 0.03125\n"
          ]
        }
      ],
      "source": [
        "i = 2082\n",
        "labels = os.listdir(labelsFolder)\n",
        "labelPath = labelsFolder + labels[i]\n",
        "f = open(labelPath, \"r\")\n",
        "txtFileContent = \"\"\n",
        "\n",
        "for x in f:\n",
        "  print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jidB_W6FJTSP"
      },
      "outputs": [],
      "source": [
        "imgPath = imagesFolder + labels[i][:-n] + replacementStr\n",
        "print('labels i ', labels[i])\n",
        "img = Image.open(imagesFolder+labels[i][:-n] + replacementStr)\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl-1Yzy2CqV7",
        "outputId": "ddfe47a6-39a1-4112-cbe1-f1c9a9c158dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total OLD images:  26104\n",
            "total OLD labels:  26104\n"
          ]
        }
      ],
      "source": [
        "images = os.listdir(imagesFolder)\n",
        "labels = os.listdir(labelsFolder)\n",
        "\n",
        "print('total OLD images: ', len(images))\n",
        "print('total OLD labels: ', len(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLaytcEEJB7N",
        "outputId": "8c60d3f8-1418-4e46-dd3c-b786f73f427d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "files removed:  13510\n"
          ]
        }
      ],
      "source": [
        "labels = os.listdir(labelsFolder)\n",
        "noOfFilesToBeRemoved = 0\n",
        "for i in range(len(labels)):\n",
        "        \n",
        "    classesInThisFile = []\n",
        "    labelPath = labelsFolder + labels[i]\n",
        "    f = open(labelPath, \"r\")\n",
        "\n",
        "    for x in f:\n",
        "        classesInThisFile.append(x[0])\n",
        "\n",
        "    f.close()\n",
        "\n",
        "    if  not(('4' in classesInThisFile) or ('2' in classesInThisFile) or ('6' in classesInThisFile)):\n",
        "        noOfFilesToBeRemoved+=1\n",
        "        \n",
        "        pathToImageBeingRemoved = imagesFolder + labels[i][:-n] + replacementStr\n",
        "\n",
        "        os.remove(pathToImageBeingRemoved)\n",
        "        os.remove(labelPath)\n",
        "print('files removed: ', noOfFilesToBeRemoved)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0aYq1fwXFLny"
      },
      "outputs": [],
      "source": [
        "!mkdir RoadSignsEdited\n",
        "!mkdir RoadSignsEdited/images\n",
        "!mkdir RoadSignsEdited/labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "oc2LjOtwi_ha"
      },
      "outputs": [],
      "source": [
        "import xml.etree.ElementTree as ET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oYQ8N373ipU5"
      },
      "outputs": [],
      "source": [
        "# Function to get the data from XML Annotation\n",
        "def extract_info_from_xml(xml_file):\n",
        "    root = ET.parse(xml_file).getroot()\n",
        "    \n",
        "    # Initialise the info dict \n",
        "    info_dict = {}\n",
        "    info_dict['bboxes'] = []\n",
        "\n",
        "    # Parse the XML Tree\n",
        "    for elem in root:\n",
        "        # Get the file name \n",
        "        if elem.tag == \"filename\":\n",
        "            info_dict['filename'] = elem.text\n",
        "            \n",
        "        # Get the image size\n",
        "        elif elem.tag == \"size\":\n",
        "            image_size = []\n",
        "            for subelem in elem:\n",
        "                image_size.append(int(subelem.text))\n",
        "            \n",
        "            info_dict['image_size'] = tuple(image_size)\n",
        "        \n",
        "        # Get details of the bounding box \n",
        "        elif elem.tag == \"object\":\n",
        "            bbox = {}\n",
        "            for subelem in elem:\n",
        "                if subelem.tag == \"name\":\n",
        "                    bbox[\"class\"] = subelem.text\n",
        "                    \n",
        "                elif subelem.tag == \"bndbox\":\n",
        "                    for subsubelem in subelem:\n",
        "                        bbox[subsubelem.tag] = int(subsubelem.text)            \n",
        "            info_dict['bboxes'].append(bbox)\n",
        "    \n",
        "    return info_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EZgH-zUukvSO"
      },
      "outputs": [],
      "source": [
        "# Dictionary that maps class names to IDs\n",
        "class_name_to_id_mapping = {\"trafficlight\": 5,\n",
        "                           \"stop\": 0,\n",
        "                           \"speedlimit\": 3,\n",
        "                           \"crosswalk\": 1}\n",
        "\n",
        "# Convert the info dict to the required yolo format and write it to disk\n",
        "def convert_to_yolov5(info_dict):\n",
        "    print_buffer = []\n",
        "    \n",
        "    # For each bounding box\n",
        "    for b in info_dict[\"bboxes\"]:\n",
        "        try:\n",
        "            class_id = class_name_to_id_mapping[b[\"class\"]]\n",
        "        except KeyError:\n",
        "            print(\"Invalid Class. Must be one from \", class_name_to_id_mapping.keys())\n",
        "        \n",
        "        # Transform the bbox co-ordinates as per the format required by YOLO v5\n",
        "        b_center_x = (b[\"xmin\"] + b[\"xmax\"]) / 2 \n",
        "        b_center_y = (b[\"ymin\"] + b[\"ymax\"]) / 2\n",
        "        b_width    = (b[\"xmax\"] - b[\"xmin\"])\n",
        "        b_height   = (b[\"ymax\"] - b[\"ymin\"])\n",
        "        \n",
        "        # Normalise the co-ordinates by the dimensions of the image\n",
        "        image_w, image_h, image_c = info_dict[\"image_size\"]  \n",
        "        b_center_x /= image_w \n",
        "        b_center_y /= image_h \n",
        "        b_width    /= image_w \n",
        "        b_height   /= image_h \n",
        "        \n",
        "        #Write the bbox details to the file \n",
        "        print_buffer.append(\"{} {:.3f} {:.3f} {:.3f} {:.3f}\".format(class_id, b_center_x, b_center_y, b_width, b_height))\n",
        "        \n",
        "    # Name of the file which we have to save \n",
        "    save_file_name = os.path.join(\"annotations\", info_dict[\"filename\"].replace(\"png\", \"txt\"))\n",
        "    \n",
        "    # Save the annotation to disk\n",
        "    print(\"\\n\".join(print_buffer), file= open(save_file_name, \"w\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sd9EVie5canH",
        "outputId": "b5b94be6-e67b-4908-c68a-73ad4d4c7386"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 877/877 [00:00<00:00, 5749.27it/s]\n"
          ]
        }
      ],
      "source": [
        "# Get the annotations\n",
        "annotations = [os.path.join('annotations', x) for x in os.listdir('annotations') if x[-3:] == \"xml\"]\n",
        "\n",
        "# Convert and save the annotations\n",
        "for ann in tqdm(annotations):\n",
        "    info_dict = extract_info_from_xml(ann)\n",
        "    convert_to_yolov5(info_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgAZHXJHdNKQ",
        "outputId": "a74ae3c6-7a38-4c68-d36a-38a44fd28006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n"
          ]
        }
      ],
      "source": [
        "#remove  crosswalk as we dont need these\n",
        "\n",
        "PathToAnnotationsInTXT = [os.path.join('annotations', x) for x in os.listdir('annotations') if x[-3:] == \"txt\"]\n",
        "\n",
        "PathToAnnotationsInXML = [os.path.join('annotations', x) for x in os.listdir('annotations') if x[-3:] == \"xml\"]\n",
        "\n",
        "for annotation in PathToAnnotationsInXML:\n",
        "  os.remove(annotation)\n",
        "\n",
        "pathToAnnotationsToBeRemoved = []\n",
        "pathToImagesToBeRemoved = []\n",
        "\n",
        "for annotation in PathToAnnotationsInTXT:\n",
        "  f = open(annotation, \"r\")\n",
        "  for x in f:\n",
        "    if(x[0] == '1'):\n",
        "      pathToAnnotationsToBeRemoved.append(annotation)\n",
        "      pathToImagesToBeRemoved.append('/content/images/' + os.path.basename(annotation).replace('txt', 'png'))\n",
        "\n",
        "print(len(pathToAnnotationsToBeRemoved))\n",
        "\n",
        "for i in range(len(pathToImagesToBeRemoved)):\n",
        "  try:\n",
        "    os.remove(pathToImagesToBeRemoved[i])\n",
        "    os.remove(pathToAnnotationsToBeRemoved[i])\n",
        "  except:\n",
        "    error = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNRMm-e7O5if",
        "outputId": "577d4967-6986-43e5-c90a-897c341f1279"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total OLD images:  707\n",
            "total OLD labels:  707\n"
          ]
        }
      ],
      "source": [
        "imagesFolder = \"/content/images\"\n",
        "images = os.listdir(imagesFolder)\n",
        "labelsFolder = \"/content/annotations\"\n",
        "labels = os.listdir(labelsFolder)\n",
        "\n",
        "print('total OLD images: ', len(images))\n",
        "print('total OLD labels: ', len(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "pmmq3F10lZJo"
      },
      "outputs": [],
      "source": [
        "def moveFilesFrom(sourceFolder, toDestFolder):\n",
        "  imagesInSourceFolder = os.listdir(sourceFolder);\n",
        "  for imageName in tqdm(imagesInSourceFolder):\n",
        "    sourceFilePath = sourceFolder + imageName\n",
        "    destFilePath = toDestFolder + imageName\n",
        "    shutil.move(sourceFilePath, destFilePath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7R4GaQyl57P"
      },
      "outputs": [],
      "source": [
        "sourceFolder = [\"/content/images/\", \"/content/annotations/\"]\n",
        "toDestFolder = [\"/content/export/images/\", \"/content/export/labels/\"]\n",
        "for i in range(len(sourceFolder)):\n",
        "  moveFilesFrom(sourceFolder[i], toDestFolder[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43dvMO0me0BH"
      },
      "outputs": [],
      "source": [
        "os.path.basename('/sdfsf/sdfdsf/erer.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "vR6ZaTVSnBOo"
      },
      "outputs": [],
      "source": [
        "# Read images and annotations\n",
        "\n",
        "trainImagesPath = \"/content/export/images/\"\n",
        "labelsPath = \"/content/export/labels/\"\n",
        "\n",
        "images = [os.path.join(trainImagesPath, x) for x in os.listdir(trainImagesPath)]\n",
        "annotations = [os.path.join(labelsPath, x) for x in os.listdir(labelsPath)]\n",
        "\n",
        "images.sort()\n",
        "annotations.sort()\n",
        "\n",
        "# Split the dataset into train-valid-test splits \n",
        "train_images, val_images, train_annotations, val_annotations = train_test_split(images, annotations, test_size = 0.1, random_state = 1)\n",
        "#val_images, test_images, val_annotations, test_annotations = train_test_split(val_images, val_annotations, test_size = 0.5, random_state = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "23MZXesTdeIN"
      },
      "outputs": [],
      "source": [
        "!mkdir train\n",
        "!mkdir train/images train/labels\n",
        "!mkdir train/images/train train/images/val train/labels/train train/labels/val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "gGgWnJCBoeV8"
      },
      "outputs": [],
      "source": [
        "#Utility function to move images \n",
        "def move_files_to_folder(list_of_files, destination_folder):\n",
        "    for f in list_of_files:\n",
        "        try:\n",
        "            shutil.move(f, destination_folder)\n",
        "        except:\n",
        "            error  = 1\n",
        "\n",
        "# Move the splits into their folders\n",
        "move_files_to_folder(train_images, 'train/images/train')\n",
        "move_files_to_folder(val_images, 'train/images/val/')\n",
        "#move_files_to_folder(test_images, 'images/test/')\n",
        "move_files_to_folder(train_annotations, 'train/labels/train/')\n",
        "move_files_to_folder(val_annotations, 'train/labels/val/')\n",
        "#move_files_to_folder(test_annotations, 'annotations/test/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNndt2PBwXbk"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "!pip install -r /content/yolov5/requirements.txt  # install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPQKgkDyLJh4",
        "outputId": "90b3aef9-2ca8-4d20-ac66-8a555c222e96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total OLD images:  11970\n",
            "total OLD labels:  11970\n"
          ]
        }
      ],
      "source": [
        "imagesFolder = \"/content/train/images/train\"\n",
        "images = os.listdir(imagesFolder)\n",
        "labelsFolder = \"/content/train/labels/train\"\n",
        "labels = os.listdir(labelsFolder)\n",
        "\n",
        "print('total OLD images: ', len(images))\n",
        "print('total OLD labels: ', len(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfXkI6a9zSzN",
        "outputId": "634c9846-1bb8-4734-8009-8fcbbb757537"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/best.pt, cfg=/content/yolov5/models/yolov5n.yaml, data=data.yaml, hyp=/content/yolov5/data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=64, imgsz=480, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=24, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-102-ge4d8360 Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n",
            "2023-02-16 00:38:04.453237: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-16 00:38:05.477005: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-02-16 00:38:05.477143: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-02-16 00:38:05.477165: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 16.8MB/s]\n",
            "Overriding model.yaml nc=80 with nc=7\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      1760  models.common.Conv                      [3, 16, 6, 2, 2]              \n",
            "  1                -1  1      4672  models.common.Conv                      [16, 32, 3, 2]                \n",
            "  2                -1  1      4800  models.common.C3                        [32, 32, 1]                   \n",
            "  3                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  4                -1  2     29184  models.common.C3                        [64, 64, 2]                   \n",
            "  5                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  6                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  7                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  8                -1  1    296448  models.common.C3                        [256, 256, 1]                 \n",
            "  9                -1  1    164608  models.common.SPPF                      [256, 256, 5]                 \n",
            " 10                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 14                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     22912  models.common.C3                        [128, 64, 1, False]           \n",
            " 18                -1  1     36992  models.common.Conv                      [64, 64, 3, 2]                \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1     74496  models.common.C3                        [128, 128, 1, False]          \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 24      [17, 20, 23]  1     16236  models.yolo.Detect                      [7, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [64, 128, 256]]\n",
            "YOLOv5n summary: 214 layers, 1773388 parameters, 1773388 gradients, 4.3 GFLOPs\n",
            "\n",
            "Transferred 348/349 items from /content/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/train/labels/train... 13301 images, 0 backgrounds, 0 corrupt: 100% 13301/13301 [00:10<00:00, 1319.78it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/train/images/train/1478021875081281646_jpg.rf.bEZPhuyXU5hIovwQSTIp.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/train/images/train/1478021875081281646_jpg.rf.e9552980cf8c6fef4aa02cb84c6364f5.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/train/images/train/1478898145212453716_jpg.rf.6a92d7d7dd523160c990c4e4375bcea9.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/train/images/train/1478898145212453716_jpg.rf.nCaFkPk4AFMjTQAM4RTJ.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/train/labels/train.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m8.4GB RAM required, 8.3/12.7GB available, not caching images ⚠️\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/train/labels/val... 1331 images, 0 backgrounds, 0 corrupt: 100% 1331/1331 [00:01<00:00, 666.75it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/train/labels/val.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.8GB ram): 100% 1331/1331 [00:18<00:00, 70.14it/s] \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.60 anchors/target, 0.999 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to yolov5/runs/train/exp/labels.jpg... \n",
            "Image sizes 480 train, 480 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1myolov5/runs/train/exp\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/29      4.13G    0.04322    0.03278     0.0023        683        480: 100% 208/208 [06:11<00:00,  1.78s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.31s/it]\n",
            "                   all       1331      10974      0.895      0.765      0.829      0.468\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/29       5.2G    0.04398      0.033   0.002338        574        480: 100% 208/208 [05:59<00:00,  1.73s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:13<00:00,  1.25s/it]\n",
            "                   all       1331      10974      0.833      0.751      0.791      0.423\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/29       5.2G    0.04441    0.03329   0.002621        545        480: 100% 208/208 [05:53<00:00,  1.70s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:17<00:00,  1.56s/it]\n",
            "                   all       1331      10974      0.689      0.598      0.644      0.358\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/29       5.2G    0.04437    0.03426   0.002876        631        480: 100% 208/208 [06:06<00:00,  1.76s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.28s/it]\n",
            "                   all       1331      10974      0.776      0.642      0.676      0.341\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/29       5.2G    0.04427    0.03419   0.002847        637        480: 100% 208/208 [06:11<00:00,  1.78s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.31s/it]\n",
            "                   all       1331      10974      0.806      0.736      0.769      0.419\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/29       5.2G    0.04362    0.03376   0.002704        563        480: 100% 208/208 [06:12<00:00,  1.79s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.28s/it]\n",
            "                   all       1331      10974      0.756      0.674      0.711      0.404\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/29       5.2G    0.04349    0.03376   0.002716        538        480: 100% 208/208 [05:55<00:00,  1.71s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:13<00:00,  1.21s/it]\n",
            "                   all       1331      10974      0.724      0.711       0.71      0.394\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/29       5.2G    0.04318    0.03349   0.002625        654        480: 100% 208/208 [05:59<00:00,  1.73s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.31s/it]\n",
            "                   all       1331      10974      0.701      0.722      0.731      0.407\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/29       5.2G    0.04298    0.03344   0.002615        624        480: 100% 208/208 [05:56<00:00,  1.71s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.31s/it]\n",
            "                   all       1331      10974      0.716      0.619      0.679      0.392\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/29       5.2G    0.04261     0.0333   0.002547        592        480: 100% 208/208 [06:01<00:00,  1.74s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.27s/it]\n",
            "                   all       1331      10974       0.77      0.676      0.736      0.403\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/29       5.2G    0.04251    0.03323   0.002478        611        480: 100% 208/208 [06:21<00:00,  1.83s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:15<00:00,  1.40s/it]\n",
            "                   all       1331      10974      0.783      0.647      0.723      0.407\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/29       5.2G     0.0423    0.03285   0.002475        679        480: 100% 208/208 [06:04<00:00,  1.75s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.34s/it]\n",
            "                   all       1331      10974      0.876       0.71      0.796        0.4\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/29       5.2G    0.04213    0.03311   0.002437        650        480: 100% 208/208 [06:03<00:00,  1.75s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.33s/it]\n",
            "                   all       1331      10974      0.793       0.76      0.731      0.414\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/29       5.2G    0.04192    0.03276   0.002371        549        480: 100% 208/208 [06:01<00:00,  1.74s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.36s/it]\n",
            "                   all       1331      10974      0.882      0.769      0.821       0.43\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/29       5.2G    0.04184    0.03269   0.002366        573        480: 100% 208/208 [05:48<00:00,  1.68s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:13<00:00,  1.26s/it]\n",
            "                   all       1331      10974      0.808      0.686      0.775      0.452\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/29       5.2G    0.04152    0.03252   0.002273        559        480: 100% 208/208 [06:01<00:00,  1.74s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:15<00:00,  1.43s/it]\n",
            "                   all       1331      10974      0.887       0.73      0.832      0.462\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/29       5.2G    0.04139    0.03247   0.002251        617        480: 100% 208/208 [06:09<00:00,  1.78s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.29s/it]\n",
            "                   all       1331      10974      0.875      0.771      0.834      0.459\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/29       5.2G    0.04104    0.03201    0.00219        691        480: 100% 208/208 [05:55<00:00,  1.71s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.33s/it]\n",
            "                   all       1331      10974      0.907      0.748      0.836      0.516\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/29       5.2G     0.0407    0.03212   0.002174        603        480: 100% 208/208 [06:04<00:00,  1.75s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:15<00:00,  1.36s/it]\n",
            "                   all       1331      10974      0.884      0.779      0.832      0.481\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/29       5.2G     0.0407    0.03209   0.002117        615        480: 100% 208/208 [05:53<00:00,  1.70s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:13<00:00,  1.21s/it]\n",
            "                   all       1331      10974      0.878      0.785       0.84      0.483\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/29       5.2G    0.04057    0.03203   0.002122        582        480: 100% 208/208 [05:28<00:00,  1.58s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.32s/it]\n",
            "                   all       1331      10974      0.898      0.777      0.843      0.486\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/29       5.2G    0.04027    0.03197   0.002066        696        480: 100% 208/208 [05:25<00:00,  1.57s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.27s/it]\n",
            "                   all       1331      10974      0.842      0.781      0.846      0.513\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/29       5.2G    0.04015    0.03177   0.002016        617        480: 100% 208/208 [05:46<00:00,  1.67s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:13<00:00,  1.22s/it]\n",
            "                   all       1331      10974      0.793      0.798      0.814      0.488\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/29       5.2G    0.04016    0.03152   0.002034        637        480: 100% 208/208 [05:37<00:00,  1.62s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:15<00:00,  1.41s/it]\n",
            "                   all       1331      10974      0.872      0.773      0.848      0.488\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/29       5.2G    0.03996    0.03158   0.002013        655        480: 100% 208/208 [06:05<00:00,  1.76s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:13<00:00,  1.27s/it]\n",
            "                   all       1331      10974      0.907      0.787      0.853      0.477\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/29       5.2G    0.03984    0.03169    0.00198        690        480: 100% 208/208 [05:53<00:00,  1.70s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.34s/it]\n",
            "                   all       1331      10974      0.881      0.806      0.853        0.5\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/29       5.2G    0.03961    0.03184    0.00192        702        480: 100% 208/208 [05:47<00:00,  1.67s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.31s/it]\n",
            "                   all       1331      10974      0.897      0.785      0.853        0.5\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/29       5.2G    0.03942    0.03134   0.001944        653        480: 100% 208/208 [05:48<00:00,  1.68s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:13<00:00,  1.23s/it]\n",
            "                   all       1331      10974       0.89      0.791      0.854      0.523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/29       5.2G    0.03913    0.03115   0.001852        625        480: 100% 208/208 [05:47<00:00,  1.67s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.27s/it]\n",
            "                   all       1331      10974      0.897        0.8      0.855      0.525\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/29       5.2G    0.03904    0.03118   0.001846        627        480: 100% 208/208 [05:46<00:00,  1.67s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.33s/it]\n",
            "                   all       1331      10974      0.872      0.815      0.857      0.526\n",
            "\n",
            "30 epochs completed in 3.095 hours.\n",
            "Optimizer stripped from yolov5/runs/train/exp/weights/last.pt, 3.8MB\n",
            "Optimizer stripped from yolov5/runs/train/exp/weights/best.pt, 3.8MB\n",
            "\n",
            "Validating yolov5/runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "YOLOv5n summary: 157 layers, 1768636 parameters, 0 gradients, 4.2 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:18<00:00,  1.66s/it]\n",
            "                   all       1331      10974      0.872      0.815      0.857      0.526\n",
            "                  stop       1331          9          1      0.969      0.995      0.872\n",
            "                   car       1331       6432      0.851      0.792      0.851      0.543\n",
            "            pedestrian       1331       2102       0.72      0.499      0.587      0.242\n",
            "            speedlimit       1331         66      0.885          1      0.991      0.821\n",
            "    trafficLight-Green       1331       1026       0.82      0.664      0.731      0.313\n",
            "          trafficlight       1331          2      0.945          1      0.995       0.43\n",
            "      trafficLight-Red       1331       1337      0.881      0.784      0.847      0.458\n",
            "Results saved to \u001b[1myolov5/runs/train/exp\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python /content/yolov5/train.py --img 480 --cfg /content/yolov5/models/yolov5n.yaml --hyp /content/yolov5/data/hyps/hyp.scratch-low.yaml --batch 64 --epochs 30 --weights '/content/best.pt' --data data.yaml --cache  --workers 24"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}